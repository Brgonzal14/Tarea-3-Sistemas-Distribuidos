`README.md`.

-----

````markdown
# Tarea 3: An√°lisis Ling√º√≠stico Offline con Hadoop y Pig

Este proyecto implementa una soluci√≥n de **Big Data** utilizando el ecosistema de **Apache Hadoop** para realizar un an√°lisis comparativo de vocabulario entre respuestas humanas (Yahoo! Answers) y respuestas generadas por Inteligencia Artificial (LLM).

El sistema utiliza una arquitectura **Batch (Offline)** donde los datos son procesados mediante scripts de **Apache Pig**, ejecutando tareas de MapReduce simplificadas para tokenizaci√≥n, limpieza y conteo de frecuencia de palabras.

---

## üèóÔ∏è Arquitectura del Sistema

El cl√∫ster est√° contenerizado con Docker y consta de los siguientes servicios:

| Servicio | Descripci√≥n |
| :--- | :--- |
| **Namenode** | Nodo maestro de Hadoop. Gestiona los metadatos del sistema de archivos distribuido (HDFS). |
| **Datanode** | Nodo esclavo que almacena los bloques de datos reales en HDFS. |
| **Pig-Client** | Contenedor cliente configurado con Apache Pig y Python. Desde aqu√≠ se inyectan los datos y se ejecutan los scripts de an√°lisis (`.pig`). |

---

## üìÇ Estructura del Proyecto

```text
TAREA_3_SISTEMAS_DISTRIBUIDOS/
‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestaci√≥n del cl√∫ster Hadoop
‚îú‚îÄ‚îÄ Dockerfile.pig        # Definici√≥n de la imagen del cliente Pig
‚îú‚îÄ‚îÄ hadoop.env            # Variables de entorno para configuraci√≥n de Hadoop
‚îú‚îÄ‚îÄ wordcount.pig         # Script de an√°lisis (Pig Latin) para conteo de palabras
‚îú‚îÄ‚îÄ yahoo_answers.txt     # Dataset: Respuestas humanas extra√≠das
‚îú‚îÄ‚îÄ llm_answers.txt       # Dataset: Respuestas generadas por IA
‚îî‚îÄ‚îÄ README.md             # Documentaci√≥n del proyecto
````

-----

## üöÄ Instrucciones de Ejecuci√≥n

### 1\. Levantar la Infraestructura

Aseg√∫rate de tener Docker Desktop corriendo y ejecuta:

```bash
docker compose up -d --build
```

*Esto descargar√° las im√°genes, construir√° el cliente de Pig e iniciar√° el cl√∫ster.*

### 2\. Preparar HDFS (Ingesta de Datos)

Una vez que los contenedores est√©n activos ("Started"), crea el directorio de entrada en el sistema de archivos distribuido:

```bash
docker exec -it pig-client hdfs dfs -mkdir -p /input
```

Carga los archivos de texto al cl√∫ster:

```bash
# Subir dataset de Yahoo
docker exec -it pig-client hdfs dfs -put /app/yahoo_answers.txt /input/

# Subir dataset del LLM
docker exec -it pig-client hdfs dfs -put /app/llm_answers.txt /input/
```

*(Opcional) Verificar la carga:*

```bash
docker exec -it pig-client hdfs dfs -ls /input
```

### 3\. Ejecutar el An√°lisis (Pig Latin)

El script `wordcount.pig` realiza las siguientes operaciones de MapReduce:

1.  **Load:** Carga las l√≠neas de texto.
2.  **Tokenize:** Divide el texto en palabras.
3.  **Clean:** Convierte a min√∫sculas y filtra signos.
4.  **Group & Count:** Agrupa por palabra y cuenta las ocurrencias.
5.  **Order:** Ordena por frecuencia descendente.
6.  **Store:** Guarda el resultado en HDFS.

Ejecuta el an√°lisis para ambos conjuntos de datos:

**Para Yahoo Answers:**

```bash
docker exec -it pig-client pig -param INPUT=/input/yahoo_answers.txt -param OUTPUT=/output/yahoo_wc /app/wordcount.pig
```

**Para LLM Answers:**

```bash
docker exec -it pig-client pig -param INPUT=/input/llm_answers.txt -param OUTPUT=/output/llm_wc /app/wordcount.pig
```

-----

## üìä Visualizaci√≥n de Resultados

Una vez finalizado el procesamiento, puedes consultar el **Top 10 de palabras m√°s frecuentes** directamente desde la terminal.

**Resultados Yahoo (Humanos):**

```bash
# En PowerShell
docker exec -it pig-client hdfs dfs -cat /output/yahoo_wc/part-r-00000 | Select-Object -First 11

# En Linux/Mac/Bash
docker exec -it pig-client hdfs dfs -cat /output/yahoo_wc/part-r-00000 | head -n 11
```

**Resultados LLM (IA):**

```bash
# En PowerShell
docker exec -it pig-client hdfs dfs -cat /output/llm_wc/part-r-00000 | Select-Object -First 11

# En Linux/Mac/Bash
docker exec -it pig-client hdfs dfs -cat /output/llm_wc/part-r-00000 | head -n 11
```

-----

## ‚èπÔ∏è Detener el Sistema

Para apagar el cl√∫ster y liberar recursos:

```bash
docker compose down
```

-----

### Autor

  * **Estudiante:** Bryan Gonz√°lez
  * **Curso:** Sistemas Distribuidos 2025-2
  * **Universidad Diego Portales**

<!-- end list -->

```
```
